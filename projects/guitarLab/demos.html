<?xml version="1.0" encoding="UTF-8"?>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en" class="js">
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
	<title>Demos | guitarLab</title>
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
	<link type="text/css" rel="stylesheet" media="all" href="css/aggregator/aggregator.css?h" />
	<link type="text/css" rel="stylesheet" media="all" href="css/node/node.css?h" />
	<link type="text/css" rel="stylesheet" media="all" href="css/system/defaults.css?h" />
	<link type="text/css" rel="stylesheet" media="all" href="css/system/system.css?h" />
	<link type="text/css" rel="stylesheet" media="all" href="css/system/system-menus.css?h" />
	<link type="text/css" rel="stylesheet" media="all" href="css/user/user.css?h" />
	<link type="text/css" rel="stylesheet" media="all" href="css/views/views.css?h" />
	<link type="text/css" rel="stylesheet" media="all" href="css/amadou/style.css?h" />
	<script type="text/javascript" src="misc/jquery.js?h"></script>
	<script type="text/javascript" src="misc/drupal.js?h"></script>
	</head>
	<body><!-- begin container --><div id="container"><!-- primary links --><div id="menu"><ul class="links"><li class="first menu-173"><a href="http://www.iiia.csic.es/en">IIIA</a></li><li class="menu-174"><a href="http://www.csic.es">CSIC</a></li></ul></div><!-- end primary links --><!-- begin header --><div id="header"><!-- site logo --><!-- end site logo --><!-- site name --><h1><a href="index.html" title="Home">guitarLab</a></h1><!-- end site name --><!-- site slogan --><!-- end site slogan --></div><!-- end header --><!-- content --><!-- begin mainContent --><div id="mainContent" style="width: 710px;"><div class="breadcrumb"><div class="breadcrumb"><a href="index.html">Home</a> :: <a href="resources.html">Resources</a>
</div></div><h1 class="pageTitle">Demos
</h1><div class="node"><div class="content"><h2>Motion Capture
</h2><p>These videos show our ongoing research collaboration with the <a href="http://www.cirmmt.mcgill.ca/">CIRMMT</a>  using the Qualisys motion capture system.<br /> First video shows a recording session (Michel Savail playing Saudade N.3 of R. Dyens). Second video shows the model obtained after processing a recording data (Michel Savail playing Leo Brouwer).
</p><p> 
</p>
<p style="text-align: center;">
	<object height="385" width="480">
		<param name="movie" value="https://www.youtube.com/v/emajyVhMZeo&amp;hl=es_ES&amp;fs=1&amp;" />
		<param name="allowFullScreen" value="true" /><param name="allowscriptaccess" value="always" />
		<embed allowfullscreen="true" allowscriptaccess="always" height="385" src="https://www.youtube.com/v/emajyVhMZeo&amp;hl=es_ES&amp;fs=1&amp;" type="application/x-shockwave-flash" width="480"></embed>
	</object>
</p><p style="text-align: center;"><object height="385" width="480"><param name="movie" value="https://www.youtube.com/v/G9KQBiFoFkc&amp;hl=es_ES&amp;fs=1&amp;" /><param name="allowFullScreen" value="true" /><param name="allowscriptaccess" value="always" /><embed allowfullscreen="true" allowscriptaccess="always" height="385" src="https://www.youtube.com/v/G9KQBiFoFkc&amp;hl=es_ES&amp;fs=1&amp;" type="application/x-shockwave-flash" width="480"></embed></object></p><h2>Hexaphonic Audio Analysis
</h2><p>These videos show the real-time capabilities of our analysis library using two different approaches. In the first video the library is used in <a href="http://www.openframeworks.cc/" target="_blank">OpenFrameworks</a> whereas the second video shows its usage as a VST plugin. Both videos show a real-time music analysis of the same guitar recording (<a href="http://www.josepsotomusic.com">Josep Soto</a> playing Bach). The left channel playing the original recording and the right channel plays the detected notes.
</p><p style="text-align: center;"><object height="385" width="480"><param name="movie" value="https://www.youtube.com/v/UQM8kYZIAlE&amp;hl=es_ES&amp;fs=1&amp;" /><param name="allowFullScreen" value="true" /><param name="allowscriptaccess" value="always" /><embed allowfullscreen="true" allowscriptaccess="always" height="385" src="https://www.youtube.com/v/UQM8kYZIAlE&amp;hl=es_ES&amp;fs=1&amp;" type="application/x-shockwave-flash" width="480"></embed></object></p><p style="text-align: center;"><object height="385" width="480"><param name="movie" value="https://www.youtube.com/v/kCH6-2TV_GA&amp;hl=es_ES&amp;fs=1&amp;" /><param name="allowFullScreen" value="true" /><param name="allowscriptaccess" value="always" /><embed allowfullscreen="true" allowscriptaccess="always" height="385" src="https://www.youtube.com/v/kCH6-2TV_GA&amp;hl=es_ES&amp;fs=1&amp;" type="application/x-shockwave-flash" width="480"></embed></object></p><h2>Artistic Experiment
</h2><p>The Master Student of the Pompeu Fabra University Heber Manuel Pérez Torres exploring artistic capabilities of the guitar prototype.
</p><p style="text-align: center;"><object height="385" width="480"><param name="movie" value="https://www.youtube.com/v/89FJj5xuP1g&amp;hl=es_ES&amp;fs=1&amp;" /><param name="allowFullScreen" value="true" /><param name="allowscriptaccess" value="always" /><embed allowfullscreen="true" allowscriptaccess="always" height="385" src="https://www.youtube.com/v/JEdzgQNFtNo&amp;hl=es_ES&amp;fs=1&amp;" type="application/x-shockwave-flash" width="480"></embed></object></p><h2>Recording Session
</h2><p>This video shows a recording session at ESMUC studio recording with our prototype (an array of capacitive sensors mounted on the fretboard of the guitar). Benjamí Abad is playing Blue Bossa.
</p><p> 
</p><p style="text-align: center;"><object height="385" width="480"><param name="movie" value="https://www.youtube.com/v/Lz2MV_qcIXk&amp;hl=es_ES&amp;fs=1&amp;" /><param name="allowFullScreen" value="true" /><param name="allowscriptaccess" value="always" /><embed allowfullscreen="true" allowscriptaccess="always" height="385" src="https://www.youtube.com/v/Lz2MV_qcIXk&amp;hl=es_ES&amp;fs=1&amp;" type="application/x-shockwave-flash" width="480"></embed></object></p><h2>Gesture detection
</h2><p>This video shows a real-time finger position detection using capacitive sensors described <a href="gAcquisition.html">here</a>. Each digit corresponds to the number of fingers pressing at the same fret. These positions can be played in different hand positions and in different strings. <i>6</i> refers to bar activation, <i>1</i> refers to 1 finger activation at any string, <i>2</i> refers to 2 finger activation at the same fret at any strings, and <i>3</i> refers to 3 finger activation at the same fret at any strings. Yellow bars and digits correspond to the detected position using a <a href="http://en.wikipedia.org/wiki/K-nearest_neighbor_algorithm" target="_blank">K-NN algorithm</a>.
</p><p style="text-align: center;"><object height="385" width="480"><param name="movie" value="https://www.youtube.com/v/89FJj5xuP1g&amp;hl=es_ES&amp;fs=1&amp;" /><param name="allowFullScreen" value="true" /><param name="allowscriptaccess" value="always" /><embed allowfullscreen="true" allowscriptaccess="always" height="385" src="https://www.youtube.com/v/89FJj5xuP1g&amp;hl=es_ES&amp;fs=1&amp;" type="application/x-shockwave-flash" width="480"></embed></object></p><p>See "Analyzing left hand fingering in guitar playing" paper in <a href="/guitarLab/publications">Publications</a> page.
</p><h2>Articulation detection
</h2><p>This video demonstrates our expressive articulation detection model. As seen on the video our algorithm works with audio input. For both F0 and onset detection we are using <a href="http://aubio.org/" target="_blank">Aubio library</a>. For each expressive articulation model, we use 40 different extracted expressive articulation. After that, we compare each articulation properties (right side) with the constructed models and classify the type of the expressive articulation. This comparison was demonstrated in the Model section (lower left) of the video. The Matlab demo will be available soon.
</p><p style="text-align: center;"><object height="385" width="480"><param name="movie" value="https://www.youtube.com/v/gG6Mh8cF8EE?fs=1&amp;hl=es_ES" /><param name="allowFullScreen" value="true" /><param name="allowscriptaccess" value="always" /><embed allowfullscreen="true" allowscriptaccess="always" height="385" src="https://www.youtube.com/v/gG6Mh8cF8EE?fs=1&amp;hl=es_ES" type="application/x-shockwave-flash" width="480"></embed></object></p><p>See "Legato and Glissando identification in Classical Guitar" paper in <a href="/guitarLab/publications">Publications</a> page.
</p><h2>Kopèrnic - Interview for TV
</h2><p>This video shows an excerpt of an interview recorded for a local TV in Barcelona. Here, we explain the main goals of this research and show the prototype we used for our initial experiments. It is in catalan.
</p><p><object height="385" width="640"><param name="movie" value="https://www.youtube.com/v/FjN7auPZaCU?fs=1&amp;hl=es_ES" /><param name="allowFullScreen" value="true" /><param name="allowscriptaccess" value="always" /><embed allowfullscreen="true" allowscriptaccess="always" height="385" src="https://www.youtube.com/v/FjN7auPZaCU?fs=1&amp;hl=es_ES" type="application/x-shockwave-flash" width="640"></embed></object></p><h2>Image-based analysis of Gestures
</h2><p>This video shows the preliminary results of our research on using computer vision techniques to analyze performers gestures and fingering. We are using <a href="http://opencv.willowgarage.com/wiki/" target="_blank">openCV</a> and <a href="http://www.openframeworks.cc/" target="_blank">OpenFrameworks</a>.
</p><p style="text-align: center;"><object height="385" width="480"><param name="movie" value="https://www.youtube.com/v/xdyHomX3hAo?fs=1&amp;hl=es_ES" /><param name="allowFullScreen" value="true" /><param name="allowscriptaccess" value="always" /><embed allowfullscreen="true" allowscriptaccess="always" height="385" src="https://www.youtube.com/v/xdyHomX3hAo?fs=1&amp;hl=es_ES" type="application/x-shockwave-flash" width="480"></embed></object></p></div></div></div><!-- end mainContent --><!-- begin sideBars --><div id="sideBars-bg" style="width: 210px;"><div id="sideBars" style="width: 210px;"><!-- left sidebar --><div id="leftSidebar"><div class="block block-menu" id="block-menu-menu-guitarlab"><h2 class="title">guitarLab
</h2><div class="content"><ul class="menu"><li class="leaf first"><a href="index.html" title="Main Page">Home</a></li><li class="expanded"><a href="research.html" title="Guitar Lab description of the project">Research</a><ul class="menu"><li class="leaf first"><a href="gAcquisition.html" title="Gesture Acquisition">Gesture Acquisition</a></li><li class="leaf"><a href="/guitarLab/research/gesture" title="Gesture Analysis">Gesture Analysis</a></li><li class="leaf last"><a href="/guitarLab/research/audio" title="Audio Analysis">Audio Analysis</a></li></ul></li><li class="expanded active-trail"><a href="resources.html" title="Available Project Resources">Resources</a><ul class="menu"><li class="leaf first"><a href="/guitarLab/resources/recordings" title="Data used in our experiments">Recordings</a></li><li class="leaf"><a href="/guitarLab/resources/prototypes" title="Discover our Guitars">Prototypes</a></li><li class="leaf active-trail"><a href="guitarLab/resources/demos" title="Demos" class="active">Demos &amp; Videos</a></li><li class="leaf last"><a href="/guitarLab/resources/slides" title="Presentations of our work">Slides &amp; Posters</a></li></ul></li><li class="leaf"><a href="/guitarLab/team" title="Team">Team</a></li><li class="leaf"><a href="/guitarLab/publications" title="Publications">Publications</a></li><li class="leaf last"><a href="/guitarLab/gallery" title="Gallery">Gallery</a></li></ul></div></div>

<div class="block block-lang_dropdown" id="block-lang_dropdown-0">

</div></div><!-- right sidebar --></div><!-- end sideBars --></div><!-- end sideBars-bg --><!-- footer --><div id="footer"><div class="block block-system" id="block-system-0"><h2 class="title"></h2></div></div><!-- end footer --></div><!-- end container -->
</body>
</html>
